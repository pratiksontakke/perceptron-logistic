{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Logistic Regression (Perceptron) Implementation\n",
        "\n",
        "This notebook implements a logistic regression model from scratch using NumPy to classify fruits (apples vs bananas) based on their physical characteristics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Logistic Regression (Perceptron) Implementation\n",
        "\n",
        "This notebook implements a logistic regression model from scratch using NumPy to classify fruits (apples vs bananas) based on their physical characteristics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 1: Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 2: Load and preprocess the data\n",
        "data = pd.read_csv('fruit.csv')\n",
        "\n",
        "# Separate features and labels\n",
        "X = data[['length_cm', 'weight_g', 'yellow_score']].values\n",
        "y = data['label'].values\n",
        "\n",
        "# Feature scaling (normalize features)\n",
        "X = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
        "\n",
        "print(\"Features shape:\", X.shape)\n",
        "print(\"Labels shape:\", y.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 3: Define the Logistic Regression class\n",
        "class LogisticRegression:\n",
        "    def __init__(self, learning_rate=0.01):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "        \n",
        "    def sigmoid(self, z):\n",
        "        \"\"\"Sigmoid activation function\"\"\"\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "    \n",
        "    def initialize_parameters(self, n_features):\n",
        "        \"\"\"Initialize weights and bias\"\"\"\n",
        "        self.weights = np.random.randn(n_features) * 0.01\n",
        "        self.bias = 0\n",
        "        \n",
        "    def forward(self, X):\n",
        "        \"\"\"Forward propagation\"\"\"\n",
        "        z = np.dot(X, self.weights) + self.bias\n",
        "        return self.sigmoid(z)\n",
        "    \n",
        "    def compute_loss(self, y_true, y_pred):\n",
        "        \"\"\"Compute binary cross-entropy loss\"\"\"\n",
        "        epsilon = 1e-15  # Small constant to avoid log(0)\n",
        "        y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
        "        return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
        "    \n",
        "    def compute_accuracy(self, y_true, y_pred):\n",
        "        \"\"\"Compute classification accuracy\"\"\"\n",
        "        predictions = (y_pred >= 0.5).astype(int)\n",
        "        return np.mean(predictions == y_true)\n",
        "    \n",
        "    def backward(self, X, y_true, y_pred):\n",
        "        \"\"\"Compute gradients\"\"\"\n",
        "        m = X.shape[0]\n",
        "        dw = np.dot(X.T, (y_pred - y_true)) / m\n",
        "        db = np.mean(y_pred - y_true)\n",
        "        return dw, db\n",
        "    \n",
        "    def train(self, X, y, epochs=500, verbose=True):\n",
        "        \"\"\"Train the model\"\"\"\n",
        "        n_features = X.shape[1]\n",
        "        self.initialize_parameters(n_features)\n",
        "        \n",
        "        history = {\n",
        "            'loss': [],\n",
        "            'accuracy': []\n",
        "        }\n",
        "        \n",
        "        for epoch in range(epochs):\n",
        "            # Forward propagation\n",
        "            y_pred = self.forward(X)\n",
        "            \n",
        "            # Compute metrics\n",
        "            loss = self.compute_loss(y, y_pred)\n",
        "            accuracy = self.compute_accuracy(y, y_pred)\n",
        "            \n",
        "            # Backward propagation\n",
        "            dw, db = self.backward(X, y, y_pred)\n",
        "            \n",
        "            # Update parameters\n",
        "            self.weights -= self.learning_rate * dw\n",
        "            self.bias -= self.learning_rate * db\n",
        "            \n",
        "            # Store metrics\n",
        "            history['loss'].append(loss)\n",
        "            history['accuracy'].append(accuracy)\n",
        "            \n",
        "            # Print progress\n",
        "            if verbose and epoch % 100 == 0:\n",
        "                print(f\"Epoch {epoch}, Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "                \n",
        "            # Early stopping if loss is small enough\n",
        "            if loss < 0.05:\n",
        "                print(f\"Reached target loss at epoch {epoch}\")\n",
        "                break\n",
        "                \n",
        "        return history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 4: Train the model\n",
        "model = LogisticRegression(learning_rate=0.1)\n",
        "history = model.train(X, y)\n",
        "\n",
        "# Print final weights\n",
        "print(\"\\nFinal model parameters:\")\n",
        "print(\"Weights:\", model.weights)\n",
        "print(\"Bias:\", model.bias)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 5: Plot the training progress\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Plot loss vs epoch\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history['loss'])\n",
        "plt.title('Loss vs Epoch')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Binary Cross-Entropy Loss')\n",
        "plt.grid(True)\n",
        "\n",
        "# Plot accuracy vs epoch\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history['accuracy'])\n",
        "plt.title('Accuracy vs Epoch')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
